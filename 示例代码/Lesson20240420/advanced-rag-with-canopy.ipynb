{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4sj2Perx6AM"
      },
      "source": [
        "## 安装依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvWYCwQUykz_"
      },
      "outputs": [],
      "source": [
        "!pip install -qU canopy-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I26-til5txw",
        "outputId": "4e93e371-f4ad-4a9b-aa2b-c5170ced64f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain_openai cohere==4.27 markdown google-search-results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_mLmRUA_Ms_"
      },
      "source": [
        "- 如果你希望在Colab上运行Canopy则运行下述代码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "gjKnxGmEYnAX",
        "outputId": "52153c85-7ade-45ff-b9ea-2cd14d6701c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.2.1.240316 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3d380ac5987e44c4810599babe3c0efc",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE_zfXrax0Hu"
      },
      "source": [
        "## Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXPY1HuI0Eqn"
      },
      "outputs": [],
      "source": [
        "# 加载各种Key\n",
        "import getpass\n",
        "import os\n",
        "print(\"Provide your Pinecone key\")\n",
        "os.environ[\"PINECONE_API_KEY\"] =  getpass.getpass()\n",
        "print(\"Provide your OpenAI API key\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
        "print(\"Provide your Serp API key\")\n",
        "os.environ[\"SERPAPI_API_KEY\"] = getpass.getpass()\n",
        "print(\"Provide your Cohere API key\")\n",
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc0kq5WryQ0I"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uMSH2Ywf1efP",
        "outputId": "85d4bf3b-ac00-4dac-b449-07f2a621cdb9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"728aeea1-1dcf-5d0a-91f2-ecccd4dd4272\",\n          \"06609e7b-6caa-5c83-a185-5e165621e44c\",\n          \"085c267b-eaae-5dc7-9d16-21073755d9a5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"# Scale indexes\\n\\n[Suggest Edits](/edit/scaling-indexes)In this topic, we explain how you can scale your indexes horizontally and vertically.\\n\\n\\nProjects in the `gcp-starter` environment do not support the features referred to here, including pods, replicas, and collections.\\n\\n\\n## Vertical vs. horizontal scaling\\n\\n\\nIf you need to scale your environment to accommodate more vectors, you can modify your existing index to scale it vertically or create a new index and scale horizontally. This article will describe both methods and how to scale your index effectively. \\n\\n\\n## Vertical scaling\\n\\n\\nScaling vertically is fast and involves no downtime. This is a good choice when you can't pause upserts and must continue serving traffic. It also allows you to double your capacity instantly. However, there are some factors to consider.\\n\\n\\nBy [changing the pod size](manage-indexes#changing-pod-sizes), you can scale to x2, x4, and x8 pod sizes, which means you are doubling your capacity at each step. Moving up to a new capacity will effectively double the number of pods used at each step. If you need to scale by smaller increments, then consider horizontal scaling. \\n\\n\\nThe number of base pods you specify when you initially create the index is static and cannot be changed. For example, if you start with 10 pods of `p1.x1` and vertically scale to `p1.x2`, this equates to 20 pods worth of usage. Neither can you change pod types with vertical scaling. If you want to change your pod type while scaling, then horizontal scaling is the better option. \\n\\n\\nYou can only scale index sizes up and cannot scale them back down.\\n\\n\\nSee our learning center for more information on [vertical scaling](https://www.pinecone.io/learn/testing-p2-collections-scaling/#vertical-scaling-on-p1-and-s1).\\n\\n\\n## Horizontal scaling\\n\\n\\nThere are two approaches to horizontal scaling in Pinecone: adding pods and adding replicas. Adding pods increases all resources but requires a pause in upserts; adding replicas only increases throughput and requires no pause in upserts.\\n\\n\\n### Adding pods\\n\\n\\nAdding pods to an index increases all resources, including available capacity. Adding pods to an existing index is possible using our <collections> feature. A collection is an immutable snapshot of your index in time: a collection stores the data but not the original index definition.\\n\\n\\nWhen you [create an index from a collection](manage-indexes#create-an-index-from-a-collection), you define the new index configuration. This allows you to scale the base pod count horizontally without scaling vertically. The main advantage of this approach is that you can scale incrementally instead of doubling capacity as with vertical scaling. Also, you can redefine pod types if you are experimenting or if you need to use a different pod type, such asperformance-optimized pods or storage-optimized pods. Another advantage of this method is that you can change your [metadata configuration](manage-indexes#selective-metadata-indexing) to redefine metadata fields as indexed or stored-only. This is important when [tuning your index](performance-tuning) for the best throughput. \\n\\n\\nHere are the general steps to make a copy of your index and create a new index while changing the pod type, pod count, metadata configuration, replicas, and all typical parameters when creating a new collection: \\n\\n\\n1. Pause upserts.\\n2. Create a collection from the current index.\\n3. Create an index from the collection with new parameters.\\n4. Continue upserts to the newly created index. Note: the URL has likely changed.\\n5. Delete the old index if desired.\\n\\n\\n### Adding replicas\\n\\n\\nEach replica duplicates the resources and data in an index. This means that adding additional replicas increases the throughput of the index but not its capacity. However, adding replicas does not require downtime.\\n\\n\\nThroughput in terms of queries per second (QPS) scales linearly with the number of replicas per index.\\n\\n\\nTo add replicas, use the `configure_index` operation to [increase the number of replicas for your index](manage-indexes#replicas).\\n\\n\\n## Next steps\\n\\n\\n* See our learning center for more information on [vertical scaling](https://www.pinecone.io/learn/testing-p2-collections-scaling/#vertical-scaling-on-p1-and-s1).\\n* Learn more about <collections>.\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n* [Table of Contents](#)\\n* + [Vertical vs. horizontal scaling](#vertical-vs-horizontal-scaling)\\n\\t+ [Vertical scaling](#vertical-scaling)\\n\\t+ [Horizontal scaling](#horizontal-scaling)\\n\\t\\t- [Adding pods](#adding-pods)\\n\\t\\t- [Adding replicas](#adding-replicas)\\n\\t+ [Next steps](#next-steps)\\n\",\n          \"# Understanding projects\\n\\n[Suggest Edits](/edit/projects)## Overview\\n\\n\\nThis document explains the concepts related to Pinecone projects.\\n\\n\\n## Projects contain indexes and users\\n\\n\\nEach Pinecone project contains a number of [indexes](/docs/indexes) and users. Only a user who belongs to the project can access the indexes in that project. Each project also has at least one project owner. All of the pods in a single project are located in a single environment. \\n\\n\\n## Project settings\\n\\n\\nWhen you create a new project, you can choose the **name**, **deployment environment**, and **pod limit**.\\n\\n\\n### Project environment\\n\\n\\nWhen creating a project, you must choose a cloud environment for the indexes in that project. Your project environment can affect your [pricing](https://pinecone.io/pricing). The following table lists the available cloud regions, the corresponding values of the `environment` parameter for the [init() operation](quickstart#2-get-and-verify-your-pinecone-api-key), and which billing tier has access to each environment:\\n\\n\\n\\n\\n| Cloud region | `environment` value | Tier availability |\\n| --- | --- | --- |\\n| GCP Starter (Iowa)\\\\* | gcp-starter | Starter |\\n| GCP US-West-1 Free (N. California) | us-west1-gcp-free | Starter |\\n| GCP Asia-Southeast-1 (Singapore) | asia-southeast1-gcp-free | Starter |\\n| GCP US-West-4 (Las Vegas) | us-west4-gcp-free | Starter |\\n| GCP US-West-1 (N. California) | us-west1-gcp | Standard / Enterprise |\\n| GCP US-Central-1 (Iowa) | us-central1-gcp | Standard / Enterprise |\\n| GCP US-West-4 (Las Vegas) | us-west4-gcp | Standard / Enterprise |\\n| GCP US-East-4 (Virginia) | us-east4-gcp | Standard / Enterprise |\\n| GCP northamerica-northeast-1 | northamerica-northeast1-gcp | Standard / Enterprise |\\n| GCP Asia-Northeast-1 (Japan) | asia-northeast1-gcp | Standard / Enterprise |\\n| GCP Asia-Southeast-1 (Singapore) | asia-southeast1-gcp | Standard / Enterprise |\\n| GCP US-East-1 (South Carolina) | us-east1-gcp | Standard / Enterprise |\\n| GCP EU-West-1 (Belgium) | eu-west1-gcp | Standard / Enterprise |\\n| GCP EU-West-4 (Netherlands) | eu-west4-gcp | Standard / Enterprise |\\n| AWS US-East-1 (Virginia) | us-east-1-aws | Standard / Enterprise |\\n| Azure East US (Virginia) | eastus-azure | Standard / Enterprise |\\n\\n\\n\\\\* This environment has unique features and limitations. See [`gcp-starter` environment](starter-environment) for more information.\\n\\n\\n [Contact us](http://www.pinecone.io/contact/) if you need a dedicated deployment in other regions.\\n\\n\\nThe environment cannot be changed after the project is created.\\n\\n\\n### Project pod limit\\n\\n\\nYou can set the maximum number of pods that can be used in total across all indexes in a project. Use this to control costs.\\n\\n\\nThe pod limit can be changed only by the project owner.\\n\\n\\n### Project roles\\n\\n\\nThere are two project roles: **Project owner** and **project member.** Table 1 below summarizes the permissions for each role.\\n\\n\\n**Table 1: Project roles and permissions**\\n\\n\\n\\n\\n| Project role | Permissions in organization |\\n| --- | --- |\\n| Project owner | Manage project members |\\n|  | Manage project API keys |\\n|  | Manage pod limits |\\n| Project member | Access API keys |\\n|  | Create indexes in project |\\n|  | Use indexes in project |\\n\\n\\n## API keys\\n\\n\\nEach Pinecone [project](projects) has one or more API keys. In order to [make calls to the Pinecone API](quickstart), a user must provide a valid API key for the relevant Pinecone project.\\n\\n\\nTo view the API key for your project, open the [Pinecone console](https://app.pinecone.io), select the project, and click **API Keys**.\\n\\n\\n## Project ID\\n\\n\\nEach Pinecone project has a project ID. This hexadecimal string appears as part of the URL for API calls. \\n\\n\\nTo find a project's ID, follow these steps:\\n\\n\\n1. Go to the [Pinecone console](https://app.pinecone.io).\\n2. In the upper-left corner, select your project.\\n3. Click **Indexes**.\\n4. Under the name of your indexes, find the index URL. For example:\\n\\n\\n`example-index-1e3g52e.svc.us-east1-gcp.pinecone.io`\\n\\n\\nThe portion of the index URL after the index name and before the dot is the project ID. \\n\\n\\nFor example, in the index URL `test-index-3e2f43f.svc.us-east1-gcp.pinecone.io`, the project ID is `3e2f43f`.\\n\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n* [Table of Contents](#)\\n* + [Overview](#overview)\\n\\t+ [Projects contain indexes and users](#projects-contain-indexes-and-users)\\n\\t+ [Project settings](#project-settings)\\n\\t\\t- [Project environment](#project-environment)\\n\\t\\t- [Project pod limit](#project-pod-limit)\\n\\t\\t- [Project roles](#project-roles)\\n\\t+ [API keys](#api-keys)\\n\\t+ [Project ID](#project-id)\\n\",\n          \"# Monitoring your usage\\n\\n[Suggest Edits](/edit/monitoring-usage)This document describes how to monitor the usage and costs for your Pinecone organization through the Pinecone console.\\n\\n\\nTo view your Pinecone usage, you must be the [organization owner](organizations#organization-owners) for your organization. This feature is only available to organizations on the Standard or Enterprise plans.\\n\\n\\nTo view your usage through the Pinecone console, follow these steps:\\n\\n\\n1. Log in to the [Pinecone console](https://app.pinecone.io).\\n2. In the left menu, click **Organizations**.\\n3. Click the **USAGE** tab.\\n\\n\\nAll dates are given in UTC to match billing invoices.\\n\\nUpdated 29 days ago \\n\\n\\n\\n---\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"https://docs.pinecone.io/docs/scaling-indexes\",\n          \"https://docs.pinecone.io/docs/projects\",\n          \"https://docs.pinecone.io/docs/monitoring-usage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ac7feb46-8a4e-4ad9-9549-cdf4d6226794\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>728aeea1-1dcf-5d0a-91f2-ecccd4dd4272</td>\n",
              "      <td># Scale indexes\\n\\n[Suggest Edits](/edit/scali...</td>\n",
              "      <td>https://docs.pinecone.io/docs/scaling-indexes</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'scaling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2f19f269-171f-5556-93f3-a2d7eabbe50f</td>\n",
              "      <td># Understanding organizations\\n\\n[Suggest Edit...</td>\n",
              "      <td>https://docs.pinecone.io/docs/organizations</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'organiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b2a71cb3-5148-5090-86d5-7f4156edd7cf</td>\n",
              "      <td># Manage datasets\\n\\n[Suggest Edits](/edit/dat...</td>\n",
              "      <td>https://docs.pinecone.io/docs/datasets</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'datasets'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1dafe68a-2e78-57f7-a97a-93e043462196</td>\n",
              "      <td># Architecture\\n\\n[Suggest Edits](/edit/archit...</td>\n",
              "      <td>https://docs.pinecone.io/docs/architecture</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'archite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd</td>\n",
              "      <td># Moving to production\\n\\n[Suggest Edits](/edi...</td>\n",
              "      <td>https://docs.pinecone.io/docs/moving-to-produc...</td>\n",
              "      <td>{'created_at': '2023_10_25', 'title': 'moving-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac7feb46-8a4e-4ad9-9549-cdf4d6226794')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac7feb46-8a4e-4ad9-9549-cdf4d6226794 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac7feb46-8a4e-4ad9-9549-cdf4d6226794');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b8f5090-6c0d-426c-bad6-33e503cbfdd9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b8f5090-6c0d-426c-bad6-33e503cbfdd9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b8f5090-6c0d-426c-bad6-33e503cbfdd9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                     id   \n",
              "0  728aeea1-1dcf-5d0a-91f2-ecccd4dd4272  \\\n",
              "1  2f19f269-171f-5556-93f3-a2d7eabbe50f   \n",
              "2  b2a71cb3-5148-5090-86d5-7f4156edd7cf   \n",
              "3  1dafe68a-2e78-57f7-a97a-93e043462196   \n",
              "4  8b07b24d-4ec2-58a1-ac91-c8e6267b9ffd   \n",
              "\n",
              "                                                text   \n",
              "0  # Scale indexes\\n\\n[Suggest Edits](/edit/scali...  \\\n",
              "1  # Understanding organizations\\n\\n[Suggest Edit...   \n",
              "2  # Manage datasets\\n\\n[Suggest Edits](/edit/dat...   \n",
              "3  # Architecture\\n\\n[Suggest Edits](/edit/archit...   \n",
              "4  # Moving to production\\n\\n[Suggest Edits](/edi...   \n",
              "\n",
              "                                              source   \n",
              "0      https://docs.pinecone.io/docs/scaling-indexes  \\\n",
              "1        https://docs.pinecone.io/docs/organizations   \n",
              "2             https://docs.pinecone.io/docs/datasets   \n",
              "3         https://docs.pinecone.io/docs/architecture   \n",
              "4  https://docs.pinecone.io/docs/moving-to-produc...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'created_at': '2023_10_25', 'title': 'scaling...  \n",
              "1  {'created_at': '2023_10_25', 'title': 'organiz...  \n",
              "2  {'created_at': '2023_10_25', 'title': 'datasets'}  \n",
              "3  {'created_at': '2023_10_25', 'title': 'archite...  \n",
              "4  {'created_at': '2023_10_25', 'title': 'moving-...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# 读取PineCone的文档数据\n",
        "data = pd.read_parquet(\"https://storage.googleapis.com/pinecone-datasets-dev/pinecone_docs_ada-002/raw/file1.parquet\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6XnAbuRyUke"
      },
      "source": [
        "## 初始化 Canopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFQVqn0x1oUo"
      },
      "outputs": [],
      "source": [
        "from canopy.knowledge_base import KnowledgeBase\n",
        "from canopy.tokenizer import Tokenizer\n",
        "Tokenizer.initialize()\n",
        "\n",
        "INDEX_NAME = \"advanced-rag\"\n",
        "kb = KnowledgeBase(index_name=INDEX_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGLmYDEwyaHZ"
      },
      "source": [
        "- 如果没有创建过Canopy index，则创建一个 Canopy index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzD8QcXg1tBm"
      },
      "outputs": [],
      "source": [
        "from canopy.knowledge_base import list_canopy_indexes\n",
        "if not any(name.endswith(INDEX_NAME) for name in list_canopy_indexes()):\n",
        "    kb.create_canopy_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70SVIAOiygS5"
      },
      "source": [
        "- 将上述导入的数据中的行数据转化为 Canopy 的文档数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d06oGvEAU5j"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import Document\n",
        "documents = [Document(**row) for _, row in data.iterrows()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rlXtS_Wyt3k"
      },
      "source": [
        "- 对文档进行Upsert操作，塞入Canopy的知识库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d3573c80a7114226bb414751494a68b2",
            "2a46132cb401493784cfc6b3ad3c794d",
            "d3aa981837014c33b484767043966f4b",
            "ec9cd65f64264b12a7a275f8d26eb86c",
            "cbe2e7ad44124a5b917c1f8bb2cc7db9",
            "babf021aafb4453783641c6fae1616c1",
            "6583ed72196c4efa843564a2ea980fca",
            "dd733b844ca246d2968fb4db085364fa",
            "9ebedfb13bb049f5bab139cab603da64",
            "00e763e75e714ba0b2c171319b252d97",
            "449f49df34624a79a2191acd68889b69"
          ]
        },
        "id": "ECcZYZ2PAbxI",
        "outputId": "9d4abb32-611b-4bb0-d527-1ff66d7e3254"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3573c80a7114226bb414751494a68b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "kb = KnowledgeBase(index_name=INDEX_NAME)\n",
        "kb.connect()\n",
        "batch_size = 10\n",
        "\n",
        "for i in tqdm(range(0, len(documents), batch_size)):\n",
        "    kb.upsert(documents[i: i+batch_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1fr52qjyy6u"
      },
      "source": [
        "- 测试Canopy的知识库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g_LbPAmaV12"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import Query\n",
        "\n",
        "results = kb.query([Query(text=\"p1 pod capacity\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRuZY0uZawwX"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNDvAGVdzDz9"
      },
      "source": [
        "## 初始化上下文和聊天引擎"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1U1MPvTcAZG1"
      },
      "outputs": [],
      "source": [
        "# 初始化上下文引擎\n",
        "from canopy.context_engine import ContextEngine\n",
        "context_engine = ContextEngine(kb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qxo0B0xedb6"
      },
      "outputs": [],
      "source": [
        "# 初始化聊天引擎\n",
        "from canopy.chat_engine import ChatEngine\n",
        "chat_engine = ChatEngine(context_engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iESlTrwFejQ5"
      },
      "outputs": [],
      "source": [
        "# 定义聊天对话函数\n",
        "from typing import Tuple\n",
        "from canopy.models.data_models import Messages, UserMessage, AssistantMessage\n",
        "\n",
        "def chat(new_message: str, history: Messages) -> Tuple[str, Messages]:\n",
        "    messages = history + [UserMessage(content=new_message)] # 历史数据 + 用户信息向大模型的作为输入\n",
        "    response = chat_engine.chat(messages)\n",
        "    assistant_response = response.choices[0].message.content\n",
        "    return assistant_response, messages + [AssistantMessage(content=assistant_response)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5gRXYTIx-kZ"
      },
      "outputs": [],
      "source": [
        "# 将string类型的数据转化为Json数据\n",
        "import json\n",
        "import ast\n",
        "\n",
        "def str_to_json(s):\n",
        "    try:\n",
        "        # First, attempt to parse the string as JSON\n",
        "        return json.loads(s)\n",
        "    except json.JSONDecodeError:\n",
        "        # If it fails, assume the string might be a Python literal\n",
        "        try:\n",
        "            return ast.literal_eval(s)\n",
        "        except (ValueError, SyntaxError):\n",
        "            # Handle the case where parsing fails for both methods\n",
        "            print(\"Error: Input string is neither valid JSON nor a valid Python literal.\")\n",
        "            return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6qtBKW9-ZWL"
      },
      "source": [
        "## 评估大模型\n",
        "\n",
        "- 在这里，我们调用大型语言模型（LLM）本身，以不同的方式评估相对于特定提示生成的文本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVBVdCvq0hz-"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_llm(model, prompt, generated_text):\n",
        "    \"\"\"\n",
        "    Uses a Large Language Model (LLM) to evaluate generated text.\n",
        "\n",
        "    :param model: An instance of the LLM, ready to generate responses.\n",
        "    :param prompt: The original prompt given to the system.\n",
        "    :param generated_text: The text generated by the SELF-RAG system.\n",
        "    :return: A dictionary containing critique scores or assessments.\n",
        "    \"\"\"\n",
        "    evaluations = {}\n",
        "\n",
        "    # 从提供的模板和关键字参数中创建评估查询\n",
        "    def create_evaluation_query(template, **kwargs):\n",
        "        query = ChatPromptTemplate.from_template(template)\n",
        "        chain = query | model\n",
        "        return float(chain.invoke(kwargs).content)\n",
        "\n",
        "    # 相关性评估\n",
        "    relevance_template = \"Given the context provided by the following prompt: '{prompt}', please evaluate on a scale from 0 to 1, where 1 is highly relevant and 0 is not relevant at all, how relevant is this generated response: '{generated_text}'? Provide a numerical score only.\"\n",
        "    evaluations['relevance'] = create_evaluation_query(relevance_template, prompt=prompt, generated_text=generated_text)\n",
        "\n",
        "    # 清晰度评估\n",
        "    clarity_template = \"How clear and easily understandable is this text: '{generated_text}'? Rate its clarity on a scale from 0 to 1, where 1 indicates that the text is very clear and 0 indicates that the text is very unclear. Provide a numerical score only.\"\n",
        "    evaluations['clarity'] = create_evaluation_query(clarity_template, prompt=prompt, generated_text=generated_text)\n",
        "\n",
        "    # 连贯性评估\n",
        "    coherence_template = \"On a scale from 0 to 1, with 1 being highly coherent and 0 being not coherent at all, how well do the ideas in this generated text: '{generated_text}' flow together? Consider if the text makes logical sense as a whole. Provide a numerical score only.\"\n",
        "    evaluations['coherence'] = create_evaluation_query(coherence_template, prompt=prompt, generated_text=generated_text)\n",
        "\n",
        "    # 详尽性评估\n",
        "    detail_template = \"Assessing the detail and exhaustiveness relative to the prompt '{prompt}', how thoroughly does this generated text: '{generated_text}' cover the topic? Rate on a scale from 0 to 1, where 1 is very detailed and exhaustive, and 0 is not detailed at all. Provide a numerical score only.\"\n",
        "    evaluations['details'] = create_evaluation_query(detail_template, prompt=prompt, generated_text=generated_text)\n",
        "\n",
        "    # 作为答案的适宜性评估\n",
        "    suitability_template = \"Evaluate the suitability of this generated text: '{generated_text}' as an answer to the original prompt '{prompt}'. On a scale from 0 to 1, where 1 is a perfect answer and 0 is completely unsuitable, provide a numerical score only.\"\n",
        "    evaluations['suitability'] = create_evaluation_query(suitability_template, prompt=prompt, generated_text=generated_text)\n",
        "\n",
        "    return evaluations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZRJQC_t-lGA"
      },
      "source": [
        "## Critique\n",
        "- 评价函数创建评估并根据可配置的权重产生加权平均值\n",
        "- 通过这种方式，可以改变每个评估得分对最终评价分数的影响"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oqAV4aE2gYV"
      },
      "outputs": [],
      "source": [
        "def critique(model, prompt, generated_text):\n",
        "    evaluation_weights = {\n",
        "        'relevance': 3,\n",
        "        'clarity': 1,\n",
        "        'coherence': 0.5,\n",
        "        'details': 1.5,\n",
        "        'suitability': 2\n",
        "    }\n",
        "\n",
        "    # 调用函数 evaluate_with_llm 来获取各维度的评估分数\n",
        "    evaluations = evaluate_with_llm(model, prompt, generated_text)\n",
        "    print(\"Evaluations:\", evaluations)\n",
        "\n",
        "    # 计算评估得分的加权和\n",
        "    weighted_sum = sum(evaluations[aspect] * evaluation_weights.get(aspect, 1) for aspect in evaluations)\n",
        "\n",
        "    # 计算评估的权重总和\n",
        "    total_weight = sum(evaluation_weights.get(aspect, 1) for aspect in evaluations)\n",
        "\n",
        "    # 计算评估得分的加权平均值\n",
        "    weighted_average = weighted_sum / total_weight if total_weight > 0 else 0\n",
        "\n",
        "    # 返回加权平均值和各维度的评估得分\n",
        "    return [weighted_average, evaluations]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p23RHPIY55v"
      },
      "outputs": [],
      "source": [
        "def is_retrieval_needed(model, prompt):\n",
        "  # 定义一个基于模板的提示，询问是否需要从外部来源检索信息来回答问题\n",
        "  is_retrieval_needed_prompt = ChatPromptTemplate.from_template(\"Given the prompt: '{prompt}', is retrieval from an external source necessary to answer the question? Reply with only True or False\")\n",
        "  # 创建一个查询链，该链首先应用模板，然后传递给模型进行处理\n",
        "  is_retrieval_needed_chain = is_retrieval_needed_prompt | model\n",
        "  # 执行查询链，并传入实际的提示文本，获取模型的回答\n",
        "  return is_retrieval_needed_chain.invoke({\"prompt\": prompt}).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpi42AhB3Uw_"
      },
      "outputs": [],
      "source": [
        "def consolidate(model, text):\n",
        "  consolidate_prompt = ChatPromptTemplate.from_template(\"Given the following set of texts, please consolidate them: '{text}'\")\n",
        "  consolidate_chain = consolidate_prompt | model\n",
        "\n",
        "  return consolidate_chain.invoke({\"text\": text}).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz1g-imTa58O"
      },
      "outputs": [],
      "source": [
        "def compare(model, query, text1, text2):\n",
        "  # 创建一个基于模板的聊天提示，指示模型整合提供的文本集\n",
        "  compare_prompt = ChatPromptTemplate.from_template(\"Given the following query: '{query}', score text1 and text2 between 0 and 1, to indicate which provides a better answer overall to the query. Reply with two numbers in an array, for example: [0.1, 0.9]. The sum total of the values should be 1. text1: '{text1}' \\n text2: '{text2}'\")\n",
        "  # 创建一个查询链，该链首先应用整合模板，然后将其传递给模型处理\n",
        "  compare_chain = compare_prompt | model\n",
        "  # 执行查询链，并传入实际的文本，获取模型整合后的内容\n",
        "  return str_to_json(compare_chain.invoke({\"query\": query, \"text1\": text1, \"text2\": text2}).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ8oJFOQbHAQ"
      },
      "outputs": [],
      "source": [
        "def generate_queries(model,prompt, num_queries):\n",
        "  # 创建一个基于模板的聊天提示，指示模型根据给定的提示生成指定数量的问题\n",
        "  query_generation_prompt = ChatPromptTemplate.from_template(\"Given the prompt: '{prompt}', generate {num_queries} questions that are better articulated. Return in the form of an list. For example: ['question 1', 'question 2', 'question 3']\")\n",
        "  # 创建一个查询链，该链首先应用生成问题的模板，然后将其传递给模型处理\n",
        "  query_generation_chain = query_generation_prompt | model\n",
        "  # 执行查询链，并传入实际的提示和问题数量，获取模型生成的问题列表\n",
        "  return str_to_json(query_generation_chain.invoke({\"prompt\": prompt, \"num_queries\": num_queries}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHyWLQxwzcv6"
      },
      "source": [
        "A helper function to get text from an array of Canopy `Document` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWOh4lelmDN4"
      },
      "outputs": [],
      "source": [
        "from canopy.models.data_models import Query\n",
        "\n",
        "def extract_documents_texts(results):\n",
        "    # 初始化一个空列表，用于存储提取的文本\n",
        "    all_texts = []\n",
        "    # 遍历结果列表中的每个QueryResult\n",
        "    for result in results:\n",
        "        # 假设result.documents是访问QueryResult中文档的正确方式\n",
        "        for document in result.documents:\n",
        "            # 假设document.text是访问DocumentWithScore中文本的正确方式\n",
        "            all_texts.append(document.text)\n",
        "    # 返回所有文本的平面列表\n",
        "    return all_texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd-2_LFBzkW8"
      },
      "source": [
        "A reranking function that queries the knowledge base, then reranks the results using Cohere's `rerank-english-v2.0` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzoVlvOlyhv6"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "# 创建Cohere客户端，使用环境变量中的API密钥\n",
        "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
        "\n",
        "\n",
        "def get_reranked_result(query, top_n=1):\n",
        "  # 使用知识库查询输入的查询词，并返回匹配结果\n",
        "  matches = kb.query([Query(text=query)])\n",
        "  # 使用先前定义的函数从匹配结果中提取所有文档的文本\n",
        "  docs = extract_documents_texts(matches)\n",
        "  # 使用Cohere的重排序模型对文档进行重排序，获取与查询最相关的顶部文档\n",
        "  rerank_results = co.rerank(model=\"rerank-english-v2.0\", query=query, documents=docs, top_n=top_n)\n",
        "  texts = []\n",
        "  # 遍历重排序的结果\n",
        "  for rerank_result in rerank_results:\n",
        "      # 从每个重排序结果中访问'document'属性中的'text'字段\n",
        "      text = rerank_result.document['text']\n",
        "      texts.append(text)\n",
        "  return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcXpLFf9w75K"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "class QueryDetail:\n",
        "    def __init__(self, query: str):\n",
        "        self.query = query\n",
        "        self.content: List[str] = []\n",
        "        self.critique_score: float = 0.0\n",
        "        self.critique_details: Dict[str, Any] = {}\n",
        "        self.retrieval_needed: bool = False\n",
        "        self.search_needed: bool = False\n",
        "\n",
        "    def add_response(self, model, search) -> None:\n",
        "        \"\"\"处理查询以添加回应，处理检索和批评。\"\"\"\n",
        "        if is_retrieval_needed(model, self.query):\n",
        "            response = \" \".join(get_reranked_result(self.query, top_n=3))\n",
        "            self.retrieval_needed = True\n",
        "        else:\n",
        "            response = \"Some generated answer\"\n",
        "            self.retrieval_needed = False\n",
        "\n",
        "        self.content.append(response)\n",
        "\n",
        "        critique_score, critique_details = critique(model, self.query, response)\n",
        "        self.critique_score = critique_score\n",
        "        self.critique_details = critique_details\n",
        "        self.search_needed = critique_score < 0.5\n",
        "\n",
        "        if self.search_needed:\n",
        "            self.search_and_add_results(search)\n",
        "\n",
        "    def search_and_add_results(self, search) -> None:\n",
        "        \"\"\"如果批评得分低，执行搜索并处理结果。\"\"\"\n",
        "        search_result_raw = search.run(self.query)\n",
        "        search_result = str_to_json(search_result_raw) or []\n",
        "        self.content.extend(search_result)\n",
        "\n",
        "class QueryProcessor:\n",
        "    def __init__(self, model, search, queries: List[str]):\n",
        "        self.model = model\n",
        "        self.search = search\n",
        "        self.queries = [QueryDetail(query) for query in queries]\n",
        "\n",
        "    def process_queries(self) -> List[QueryDetail]:\n",
        "        \"\"\"处理列表中的每个查询。\"\"\"\n",
        "        for query_detail in self.queries:\n",
        "            query_detail.add_response(self.model, self.search)\n",
        "            if query_detail.search_needed:\n",
        "                consolidated_response = consolidate(self.model, query_detail.content)\n",
        "                query_detail.content = [consolidated_response]\n",
        "                critique_score, critique_details = critique(self.model, query_detail.query, consolidated_response)\n",
        "                query_detail.critique_score = critique_score\n",
        "                query_detail.critique_details = critique_details\n",
        "        return self.queries\n",
        "\n",
        "def advanced_rag_query(model, query: str, num_queries: int) -> List[QueryDetail]:\n",
        "    search = SerpAPIWrapper()\n",
        "    initial_queries = generate_queries(model, query, num_queries)[:num_queries]\n",
        "    query_processor = QueryProcessor(model, search, initial_queries)\n",
        "    processed_queries = query_processor.process_queries()\n",
        "    return processed_queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUYPn898IGo_"
      },
      "outputs": [],
      "source": [
        "query = \"How can I make a new Pinecone index?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhqjVh8yzYFX"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "model = ChatOpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp98cMcj3_N5",
        "outputId": "4dfbf69c-95c3-4296-c04a-d1914a03981e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluations: {'relevance': 0.875, 'clarity': 0.8, 'coherence': 0.9, 'details': 0.8, 'suitability': 0.85}\n",
            "Evaluations: {'relevance': 1.0, 'clarity': 0.8, 'coherence': 0.8, 'details': 0.9, 'suitability': 0.8}\n",
            "Evaluations: {'relevance': 1.0, 'clarity': 0.8, 'coherence': 0.9, 'details': 0.9, 'suitability': 0.9}\n"
          ]
        }
      ],
      "source": [
        "results = advanced_rag_query(model, query, 3)\n",
        "combined_content = \" \".join(content for result in results for content in result.content)\n",
        "advanced_rag_results = consolidate(model, combined_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwL_8IVtv7sn",
        "outputId": "5897e49a-ff1e-44e9-d6d6-4ad86bd8d88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluations: {'relevance': 1.0, 'clarity': 0.85, 'coherence': 1.0, 'details': 0.8, 'suitability': 1.0}\n"
          ]
        }
      ],
      "source": [
        "advanced_rag_critique = critique(model, query, advanced_rag_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVs_ReYcwO9f",
        "outputId": "31c15ba0-f0c9-46ac-8477-4b2157604c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluations: {'relevance': 1.0, 'clarity': 0.8, 'coherence': 1.0, 'details': 0.9, 'suitability': 1.0}\n"
          ]
        }
      ],
      "source": [
        "history = []\n",
        "rag_result, history = chat(query, history)\n",
        "rag_critique = critique(model, query, rag_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "AajdOKllvmgi",
        "outputId": "72090457-eb9f-4e29-ab4c-c27940629ea4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<table>\n",
              "<tr>\n",
              "    <th>Advanced RAG</th>\n",
              "    <th>RAG</th>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td><p>To create an index in Pinecone, first download a pre-embedded dataset from the <code>pinecone-datasets</code> library. This allows you to skip the embedding and preprocessing steps. </p>\n",
              "<p>```python\n",
              "import pinecone_datasets</p>\n",
              "<p>dataset = pinecone_datasets.load_dataset('wikipedia-simple-text-embedding-ada-002-100K')\n",
              "dataset.head()\n",
              "```</p>\n",
              "<p>After downloading the data, initialize your Pinecone environment and create your first index. You have the option to select a distance metric for your index. </p>\n",
              "<p><strong>Note</strong> - By default, all fields are indexed. To avoid redundant and costly indexing, pass an additional empty metadata_config parameter.</p>\n",
              "<p><code>python\n",
              "pinecone.create_index(\n",
              "        name=index_name_v1,\n",
              "        metric='cosine',\n",
              "        dimension=1536,\n",
              "        metadata_config={“indexed”:[]} \n",
              ")</code></p>\n",
              "<p>Before creating an index, ensure your Pinecone API key is set up. If the 'openai' index already exists, you can connect to it directly.</p>\n",
              "<p>```python\n",
              "import pinecone</p>\n",
              "<p>pinecone.init(\n",
              "    api_key=\"YOUR_API_KEY\",\n",
              "    environment=\"YOUR_ENV\"\n",
              ")</p>\n",
              "<p>if 'openai' not in pinecone.list_indexes():\n",
              "    pinecone.create_index('openai', dimension=len(embeds[0]))</p>\n",
              "<p>index = pinecone.Index('openai')\n",
              "```</p>\n",
              "<p>When preparing your project structure, consider creating separate projects for your development and production indexes. This allows you to test changes before deploying them to production. Ensure that you have properly configured user access to your production environment. </p>\n",
              "<p>Before moving your index to production, test that your index is returning accurate results in the context of your application. Consider identifying the appropriate metrics for evaluating your results.</p></td>\n",
              "    <td><p>To create a new Pinecone index, you can follow these general steps:</p>\n",
              "<ol>\n",
              "<li>Initialize a connection to Pinecone using your API key and environment.</li>\n",
              "<li>Check if the index already exists, and if not, create a new index with a specified dimension.</li>\n",
              "<li>Connect to the newly created index for further operations.</li>\n",
              "</ol>\n",
              "<p>You can also consider specifying additional configurations and choices like the distance metric and metadata fields during the index creation process.</p></td>\n",
              "</tr>\n",
              "<tr>\n",
              "    <td><p>[0.94375, {'relevance': 1.0, 'clarity': 0.85, 'coherence': 1.0, 'details': 0.8, 'suitability': 1.0}]</p></td>\n",
              "    <td><p>[0.95625, {'relevance': 1.0, 'clarity': 0.8, 'coherence': 1.0, 'details': 0.9, 'suitability': 1.0}]</p></td>\n",
              "</tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "import markdown\n",
        "\n",
        "# Convert your Markdown content and critiques to strings, assuming they might not be strings already\n",
        "final_result_html = markdown.markdown(str(advanced_rag_results))\n",
        "rag_result_html = markdown.markdown(str(rag_result))\n",
        "advanced_rag_critique_html = markdown.markdown(str(advanced_rag_critique))\n",
        "rag_critique_html = markdown.markdown(str(rag_critique))\n",
        "\n",
        "# Construct HTML table with the pre-rendered HTML content for each cell\n",
        "html = f\"\"\"\n",
        "<table>\n",
        "<tr>\n",
        "    <th>Advanced RAG</th>\n",
        "    <th>RAG</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>{final_result_html}</td>\n",
        "    <td>{rag_result_html}</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>{advanced_rag_critique_html}</td>\n",
        "    <td>{rag_critique_html}</td>\n",
        "</tr>\n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "# Display the HTML table\n",
        "display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpiljdF5wzRP",
        "outputId": "3285fcb0-ba65-4406-949d-33e246a38f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.9, 0.1]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare(model, query, advanced_rag_results, rag_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00e763e75e714ba0b2c171319b252d97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a46132cb401493784cfc6b3ad3c794d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_babf021aafb4453783641c6fae1616c1",
            "placeholder": "​",
            "style": "IPY_MODEL_6583ed72196c4efa843564a2ea980fca",
            "value": "100%"
          }
        },
        "449f49df34624a79a2191acd68889b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6583ed72196c4efa843564a2ea980fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ebedfb13bb049f5bab139cab603da64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "babf021aafb4453783641c6fae1616c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe2e7ad44124a5b917c1f8bb2cc7db9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3573c80a7114226bb414751494a68b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a46132cb401493784cfc6b3ad3c794d",
              "IPY_MODEL_d3aa981837014c33b484767043966f4b",
              "IPY_MODEL_ec9cd65f64264b12a7a275f8d26eb86c"
            ],
            "layout": "IPY_MODEL_cbe2e7ad44124a5b917c1f8bb2cc7db9"
          }
        },
        "d3aa981837014c33b484767043966f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd733b844ca246d2968fb4db085364fa",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ebedfb13bb049f5bab139cab603da64",
            "value": 6
          }
        },
        "dd733b844ca246d2968fb4db085364fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9cd65f64264b12a7a275f8d26eb86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00e763e75e714ba0b2c171319b252d97",
            "placeholder": "​",
            "style": "IPY_MODEL_449f49df34624a79a2191acd68889b69",
            "value": " 6/6 [00:14&lt;00:00,  2.30s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
