{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eIj_Rfa-kuSq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get('OpenAI-Key')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!openai migrate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsZ-5xXm2s63",
        "outputId": "a97188f3-a500-4a48-966b-b77dfb71d9b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.10.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Retrieving Grit CLI metadata from https://api.keygen.sh/v1/accounts/custodian-dev/artifacts/marzano-linux-x64\n",
            "\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2mFinding files                                                         \u001b[0m\n",
            "\u001b[2K\u001b[2AProcessed 0 files and found 0 matches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary Python libraries\n",
        "import os\n",
        "import json\n",
        "import openai"
      ],
      "metadata": {
        "id": "NANJRekJ2qEW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
        ")"
      ],
      "metadata": {
        "id": "EWOR7dF92_qm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_me = 'Hello! My name is David Hundley. I am a principal machine learning engineer at State Farm. I enjoy learning about AI and teaching what I learn back to others. I have two daughters. I drive a Tesla Model 3, and my favorite video game series is The Legend of Zelda.'"
      ],
      "metadata": {
        "id": "r52ZaYZV20kc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Engineering a prompt to extract as much information from \"About Me\" as a JSON object\n",
        "about_me_prompt = f'''\n",
        "Please extract information as a JSON object. Please look for the following pieces of information.\n",
        "Name\n",
        "Job title\n",
        "Company\n",
        "Number of children as a single number\n",
        "Car make\n",
        "Car model\n",
        "Favorite video game series\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{about_me}\n",
        "'''"
      ],
      "metadata": {
        "id": "jc4ACCwV23uf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': about_me_prompt}]\n",
        ")"
      ],
      "metadata": {
        "id": "V80ZHQyQ25Yd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.model_dump_json(indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLdjIi6H6hFs",
        "outputId": "c255fee5-cb6a-4792-8570-ecf4b5e78266"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8nj3jt0WWpzc21IAaRw4CL1WWTC0S\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"{\\n  \\\"Name\\\": \\\"David Hundley\\\",\\n  \\\"Job title\\\": \\\"Principal machine learning engineer\\\",\\n  \\\"Company\\\": \\\"State Farm\\\",\\n  \\\"Number of children\\\": 2,\\n  \\\"Car make\\\": \\\"Tesla\\\",\\n  \\\"Car model\\\": \\\"Model 3\\\",\\n  \\\"Favorite video game series\\\": \\\"The Legend of Zelda\\\"\\n}\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706861971,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 70,\n",
            "    \"prompt_tokens\": 122,\n",
            "    \"total_tokens\": 192\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfed_response = completion.model_dump_json(indent=2)"
      ],
      "metadata": {
        "id": "hqsO1tSd6AyR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.loads(tfed_response)['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfbSlX8D79_b",
        "outputId": "42d16ffe-5e37-487c-d71e-14a568112a9b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Name\": \"David Hundley\",\n",
            "  \"Job title\": \"Principal machine learning engineer\",\n",
            "  \"Company\": \"State Farm\",\n",
            "  \"Number of children\": 2,\n",
            "  \"Car make\": \"Tesla\",\n",
            "  \"Car model\": \"Model 3\",\n",
            "  \"Favorite video game series\": \"The Legend of Zelda\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the response as a JSON object\n",
        "json_response = json.loads(tfed_response)['choices'][0]['message']['content']\n",
        "# print(type(json_response))\n",
        "json.loads(json_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-voSKugZ4PDw",
        "outputId": "5e3509f0-b054-40f0-f11e-0884cdb26759"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Name': 'David Hundley',\n",
              " 'Job title': 'Principal machine learning engineer',\n",
              " 'Company': 'State Farm',\n",
              " 'Number of children': 2,\n",
              " 'Car make': 'Tesla',\n",
              " 'Car model': 'Model 3',\n",
              " 'Favorite video game series': 'The Legend of Zelda'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our initial extract_person_info function\n",
        "def extract_person_info(name, job_title, num_children):\n",
        "    '''\n",
        "    Prints basic \"About Me\" information\n",
        "\n",
        "    Inputs:\n",
        "        name (str): Name of the person\n",
        "        job_title (str): Job title of the person\n",
        "        num_chilren (int): The number of children the parent has.\n",
        "    '''\n",
        "\n",
        "    print(f'This person\\'s name is {name}. Their job title is {job_title}, and they have {num_children} children.')\n"
      ],
      "metadata": {
        "id": "ZMt2OGGFAJFq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining how we want ChatGPT to call our custom functions\n",
        "my_custom_functions = [\n",
        "    {\n",
        "        'name': 'extract_person_info',\n",
        "        'description': 'Get \"About Me\" information from the body of the input text',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'name': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the person'\n",
        "                },\n",
        "                'job_title': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Job title of the person'\n",
        "                },\n",
        "                'num_children': {\n",
        "                    'type': 'integer',\n",
        "                    'description': 'Number of children the person is a parent to'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "UlFHK_IeALAp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': about_me}],\n",
        "    functions = my_custom_functions,\n",
        "    function_call = 'auto'\n",
        ")\n",
        "\n",
        "response = openai_response.model_dump_json(indent=2)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTUnswJdAhy_",
        "outputId": "db2b1b1e-d24e-410d-cdde-15fec467db84"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8njXvENfoMcTXwgtUixosRFZTWBm3\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"function_call\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": {\n",
            "          \"arguments\": \"{\\n  \\\"name\\\": \\\"David Hundley\\\",\\n  \\\"job_title\\\": \\\"Principal Machine Learning Engineer\\\",\\n  \\\"num_children\\\": 2\\n}\",\n",
            "          \"name\": \"extract_person_info\"\n",
            "        },\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706863843,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 37,\n",
            "    \"prompt_tokens\": 147,\n",
            "    \"total_tokens\": 184\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
        "openai_response = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [{'role': 'user', 'content': 'How tall is the Eiffel Tower?'}],\n",
        "    functions = my_custom_functions,\n",
        "    function_call = 'auto'\n",
        ")\n",
        "\n",
        "response = openai_response.model_dump_json(indent=2)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hULU0dSKA-tx",
        "outputId": "4c28bb4c-d016-4c6b-f82f-9809a1b16f69"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-8njYgrkmOoO6pxPKPBiCrxMmtMpEp\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The Eiffel Tower is approximately 330 meters (1,083 feet) tall.\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706863890,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 19,\n",
            "    \"prompt_tokens\": 97,\n",
            "    \"total_tokens\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to extract only vehicle information\n",
        "def extract_vehicle_info(vehicle_make, vehicle_model):\n",
        "    '''\n",
        "    Prints basic vehicle information\n",
        "\n",
        "    Inputs:\n",
        "        - vehicle_make (str): Make of the vehicle\n",
        "        - vehicle_model (str): Model of the vehicle\n",
        "    '''\n",
        "\n",
        "    print(f'Vehicle make: {vehicle_make}\\nVehicle model: {vehicle_model}')\n",
        "\n",
        "\n",
        "\n",
        "# Defining a function to extract all information provided in the original \"About Me\" prompt\n",
        "def extract_all_info(name, job_title, num_children, vehicle_make, vehicle_model, company_name, favorite_vg_series):\n",
        "    '''\n",
        "    Prints the full \"About Me\" information\n",
        "\n",
        "    Inputs:\n",
        "        - name (str): Name of the person\n",
        "        - job_title (str): Job title of the person\n",
        "        - num_chilren (int): The number of children the parent has\n",
        "        - vehicle_make (str): Make of the vehicle\n",
        "        - vehicle_model (str): Model of the vehicle\n",
        "        - company_name (str): Name of the company the person works for\n",
        "        - favorite_vg_series (str): Person's favorite video game series.\n",
        "    '''\n",
        "\n",
        "    print(f'''\n",
        "    This person\\'s name is {name}. Their job title is {job_title}, and they have {num_children} children.\n",
        "    They drive a {vehicle_make} {vehicle_model}.\n",
        "    They work for {company_name}.\n",
        "    Their favorite video game series is {favorite_vg_series}.\n",
        "    ''')"
      ],
      "metadata": {
        "id": "gR7OJkF9BFyf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining how we want ChatGPT to call our custom functions\n",
        "my_custom_functions = [\n",
        "    {\n",
        "        'name': 'extract_person_info',\n",
        "        'description': 'Get \"About Me\" information from the body of the input text',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'name': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the person'\n",
        "                },\n",
        "                'job_title': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Job title of the person'\n",
        "                },\n",
        "                'num_children': {\n",
        "                    'type': 'integer',\n",
        "                    'description': 'Number of children the person is a parent to'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'extract_vehicle_info',\n",
        "        'description': 'Extract the make and model of the person\\'s car',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'vehicle_make': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Make of the person\\'s vehicle'\n",
        "                },\n",
        "                'vehicle_model': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Model of the person\\'s vehicle'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'extract_all_info',\n",
        "        'description': 'Extract all information about a person including their vehicle make and model',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'name': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the person'\n",
        "                },\n",
        "                'job_title': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Job title of the person'\n",
        "                },\n",
        "                'num_children': {\n",
        "                    'type': 'integer',\n",
        "                    'description': 'Number of children the person is a parent to'\n",
        "                },\n",
        "                'vehicle_make': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Make of the person\\'s vehicle'\n",
        "                },\n",
        "                'vehicle_model': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Model of the person\\'s vehicle'\n",
        "                },\n",
        "                'company_name': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the company the person works for'\n",
        "                },\n",
        "                'favorite_vg_series': {\n",
        "                    'type': 'string',\n",
        "                    'description': 'Name of the person\\'s favorite video game series'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "WVwr8mxRBNrq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a list of samples\n",
        "samples = [\n",
        "    str(about_me),\n",
        "    'My name is David Hundley. I am a principal machine learning engineer, and I have two daughters.',\n",
        "    'She drives a Kia Sportage.'\n",
        "]"
      ],
      "metadata": {
        "id": "KTDlCp85BSjY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating over the three samples\n",
        "for i, sample in enumerate(samples):\n",
        "\n",
        "    print(f'Sample #{i + 1}\\'s results:')\n",
        "\n",
        "    # Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
        "    openai_response = client.chat.completions.create(\n",
        "        model = 'gpt-3.5-turbo',\n",
        "        messages = [{'role': 'user', 'content': sample}],\n",
        "        functions = my_custom_functions,\n",
        "        function_call = 'auto'\n",
        "    )\n",
        "\n",
        "    # Printing the sample's response\n",
        "    response = openai_response.model_dump_json(indent=2)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2DtPkr_BVU_",
        "outputId": "46f37b9a-f6c4-49c3-9647-7540a8ce7f01"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample #1's results:\n",
            "{\n",
            "  \"id\": \"chatcmpl-8njaqRHPPCMQ7VtPhXjPBMsRhcuBA\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"function_call\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": {\n",
            "          \"arguments\": \"{\\n  \\\"name\\\": \\\"David Hundley\\\",\\n  \\\"job_title\\\": \\\"principal machine learning engineer\\\",\\n  \\\"num_children\\\": 2,\\n  \\\"vehicle_make\\\": \\\"Tesla\\\",\\n  \\\"vehicle_model\\\": \\\"Model 3\\\",\\n  \\\"company_name\\\": \\\"State Farm\\\",\\n  \\\"favorite_vg_series\\\": \\\"The Legend of Zelda\\\"\\n}\",\n",
            "          \"name\": \"extract_all_info\"\n",
            "        },\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706864024,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 77,\n",
            "    \"prompt_tokens\": 320,\n",
            "    \"total_tokens\": 397\n",
            "  }\n",
            "}\n",
            "Sample #2's results:\n",
            "{\n",
            "  \"id\": \"chatcmpl-8njas4yIuQrp3ZOGSzq9EcGY84U1w\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"function_call\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": {\n",
            "          \"arguments\": \"{\\n\\\"name\\\": \\\"David Hundley\\\",\\n\\\"job_title\\\": \\\"Principal Machine Learning Engineer\\\",\\n\\\"num_children\\\": 2\\n}\",\n",
            "          \"name\": \"extract_all_info\"\n",
            "        },\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706864026,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 33,\n",
            "    \"prompt_tokens\": 282,\n",
            "    \"total_tokens\": 315\n",
            "  }\n",
            "}\n",
            "Sample #3's results:\n",
            "{\n",
            "  \"id\": \"chatcmpl-8njatDX418c0wbJer9dLurUM0AxUp\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"function_call\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": {\n",
            "          \"arguments\": \"{\\n  \\\"vehicle_make\\\": \\\"Kia\\\",\\n  \\\"vehicle_model\\\": \\\"Sportage\\\"\\n}\",\n",
            "          \"name\": \"extract_vehicle_info\"\n",
            "        },\n",
            "        \"tool_calls\": null\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1706864027,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 27,\n",
            "    \"prompt_tokens\": 268,\n",
            "    \"total_tokens\": 295\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterating over the three samples\n",
        "for i, sample in enumerate(samples):\n",
        "\n",
        "    print(f'Sample #{i + 1}\\'s results:')\n",
        "\n",
        "    # Getting the response back from ChatGPT (gpt-3.5-turbo)\n",
        "\n",
        "    openai_response = json.loads(client.chat.completions.create(\n",
        "        model = 'gpt-3.5-turbo',\n",
        "        messages = [{'role': 'user', 'content': sample}],\n",
        "        functions = my_custom_functions,\n",
        "        function_call = 'auto'\n",
        "    ).model_dump_json(indent=2))['choices'][0]['message']\n",
        "\n",
        "    # Checking to see that a function call was invoked\n",
        "    if openai_response.get('function_call'):\n",
        "\n",
        "        # Checking to see which specific function call was invoked\n",
        "        function_called = openai_response['function_call']['name']\n",
        "\n",
        "        # Extracting the arguments of the function call\n",
        "        function_args = json.loads(openai_response['function_call']['arguments'])\n",
        "\n",
        "        # Invoking the proper functions\n",
        "        if function_called == 'extract_person_info':\n",
        "            extract_person_info(*list(function_args.values()))\n",
        "        elif function_called == 'extract_vehicle_info':\n",
        "            extract_vehicle_info(*list(function_args.values()))\n",
        "        elif function_called == 'extract_all_info':\n",
        "            extract_all_info(*list(function_args.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN-5CZoqBsdM",
        "outputId": "71874cab-22ea-4188-9811-30cb31f97f02"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample #1's results:\n",
            "\n",
            "    This person's name is David Hundley. Their job title is Principal Machine Learning Engineer, and they have 2 children.\n",
            "    They drive a Tesla Model 3.\n",
            "    They work for State Farm.\n",
            "    Their favorite video game series is The Legend of Zelda.\n",
            "    \n",
            "Sample #2's results:\n",
            "This person's name is David Hundley. Their job title is Principal Machine Learning Engineer, and they have 2 children.\n",
            "Sample #3's results:\n",
            "Vehicle make: Kia\n",
            "Vehicle model: Sportage\n"
          ]
        }
      ]
    }
  ]
}